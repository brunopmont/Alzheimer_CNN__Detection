{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o modelo\n",
    "def create_model_old(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        # Camada 1\n",
    "        Conv3D(32, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 2\n",
    "        Conv3D(64, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 3\n",
    "        Conv3D(128, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        Conv3D(128, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 4\n",
    "        Conv3D(256, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        Conv3D(256, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 5\n",
    "        Conv3D(512, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        Conv3D(512, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Flatten e camadas densas\n",
    "        Flatten(),\n",
    "        Dense(512, activation='elu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(512, activation='elu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # Camada de saída\n",
    "        Dense(3, activation='softmax')  # 3 classes: CN, MCI, AD\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        # Camada 1\n",
    "        Conv3D(32, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 2\n",
    "        Conv3D(64, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada 3\n",
    "        Conv3D(128, (3, 3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2), padding='same'),\n",
    "\n",
    "        # Camada densa com redução de neurônios\n",
    "        Flatten(),\n",
    "        Dense(256, activation='elu'),  # Reduzido de 512 para 256\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128, activation='elu'),  # Reduzido de 512 para 128\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        # Camada de saída\n",
    "        Dense(3, activation='softmax')  # 3 classes: CN, MCI, AD\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Função para carregar imagens NIfTI, seus rótulos e cortar as imagens\n",
    "def load_nifti_images_with_labels(base_dir, slice_idx):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Caminhos das subpastas\n",
    "    for label in ['cn', 'mci', 'ad']:\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        for fname in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, fname)\n",
    "            img = nib.load(img_path).get_fdata()\n",
    "            img_cropped = img[slice_idx[0], slice_idx[1], slice_idx[2]]\n",
    "            images.append(img_cropped)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Codificando os rótulos\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    return np.array(images), labels_encoded, label_encoder.classes_\n",
    "\n",
    "# Função para carregar imagens NIfTI, seus rótulos e cortar as imagens\n",
    "def load_nifti_paths(base_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Caminhos das subpastas\n",
    "    for label in ['cn', 'mci', 'ad']:\n",
    "        label_dir = os.path.join(base_dir, label)\n",
    "        for fname in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, fname)\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Codificando os rótulos\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # Transformando os rótulos para one-hot encoding\n",
    "    labels_one_hot = to_categorical(labels_encoded, num_classes=3)\n",
    "\n",
    "    \n",
    "    return image_paths, labels_one_hot\n",
    "\n",
    "\n",
    "# Função para carregar imagem NIfTI com corte\n",
    "def load_nifti_image_with_crop(file_path, crop_slices):\n",
    "    img = nib.load(file_path)\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Aplicando os cortes (slice) nas três dimensões\n",
    "    cropped_data = data[crop_slices[0], crop_slices[1], crop_slices[2]]\n",
    "    \n",
    "    return cropped_data\n",
    "\n",
    "# Função geradora para carregar imagens em lotes com corte, reshape e shuffle\n",
    "def image_generator(file_paths, labels, crop_slices, batch_size=32, shuffle_data=True):\n",
    "    batch_input = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    # Embaralhando os dados se necessário\n",
    "    if shuffle_data:\n",
    "        file_paths, labels = shuffle(file_paths, labels)\n",
    "\n",
    "    while True:\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            # Carregar a imagem com corte\n",
    "            data = load_nifti_image_with_crop(file_path, crop_slices)\n",
    "            \n",
    "            # Aplique o reshape aqui, caso necessário (exemplo: 3D para 2D)\n",
    "            # Exemplo de reshape (ajuste conforme seu modelo):\n",
    "            data = np.expand_dims(data, axis=-1)  # Se for necessário adicionar um canal\n",
    "            \n",
    "            # Adiciona ao lote\n",
    "            batch_input.append(data)\n",
    "            batch_labels.append(labels[i])\n",
    "            \n",
    "            # Se o tamanho do lote for atingido, retorna o lote\n",
    "            if len(batch_input) == batch_size:\n",
    "                yield np.array(batch_input), np.array(batch_labels)\n",
    "                batch_input, batch_labels = [], []  # Reinicia o lote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(\"/mnt/c/Users/Team Taiane/Desktop/ADNI/Lil_adni/ADNI1_ADNI2\")\n",
    "\n",
    "# Definindo caminhos\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "results_dir = os.path.join(base_dir, 'results')\n",
    "\n",
    "# Índices de corte para o corte NIfTI\n",
    "SLICE_NII_IDX0 = slice(24, 169)\n",
    "SLICE_NII_IDX1 = slice(24, 206)\n",
    "SLICE_NII_IDX2 = slice(6, 161)\n",
    "\n",
    "# Passando os índices de corte (como uma tupla) para a função geradora\n",
    "crop_slices = (SLICE_NII_IDX0, SLICE_NII_IDX1, SLICE_NII_IDX2)\n",
    "\n",
    "img_paths_train, labels_train = load_nifti_paths(train_dir)\n",
    "img_paths_val, labels_val = load_nifti_paths(train_dir)\n",
    "\n",
    "# Criar o gerador de dados para treino e validação\n",
    "train_gen = image_generator(img_paths_train, labels_train, crop_slices, batch_size=16)\n",
    "val_gen = image_generator(img_paths_val, labels_val, crop_slices, batch_size=16)\n",
    "\n",
    "\n",
    "# Criar o diretório de resultados se ele não existir\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados com cortes\n",
    "train_images, train_labels, class_labels = load_nifti_images_with_labels(train_dir, \n",
    "                                                                        (SLICE_NII_IDX0, SLICE_NII_IDX1, SLICE_NII_IDX2))\n",
    "val_images, val_labels, _ = load_nifti_images_with_labels(val_dir, \n",
    "                                                           (SLICE_NII_IDX0, SLICE_NII_IDX1, SLICE_NII_IDX2))\n",
    "\n",
    "# Adicionar a dimensão do canal\n",
    "train_images = train_images.reshape((-1, *train_images.shape[1:], 1))\n",
    "val_images = val_images.reshape((-1, *val_images.shape[1:], 1))\n",
    "\n",
    "# Embaralhar os dados\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "val_images, val_labels = shuffle(val_images, val_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de aprendizado\n",
    "learning_rate = 1e-3\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compila model\n",
    "input_shape = (145, 182, 155, 1)\n",
    "model = create_model(input_shape)\n",
    "#model = load_model(os.path.join('results', 'test_2', 'trained_model.h5'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(os.listdir(results_dir))\n",
    "folder_name = \"test_\" + str(n+1)\n",
    "results_dir = os.path.join(results_dir, folder_name)\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "print(n)\n",
    "print(folder_name)\n",
    "print(results_dir)\n",
    "\n",
    "config = model.get_config()\n",
    "print(config)\n",
    "\n",
    "'''with open(os.path.join(results_dir, \"model_hyperparameters.txt\"), \"w\") as f:\n",
    "        f.write(model.get_config())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=25,\n",
    "    verbose=1,\n",
    "    #callbacks=[early_stopping, reduce_lr],\n",
    "    steps_per_epoch=len(img_paths_train) // 16,  # Número de batches por época\n",
    "    validation_steps=len(img_paths_val) // 16,  # Número de batches de validação\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Salva o modelo, arquitetura, pesos e estado do otimizador\n",
    "model.save(os.path.join(results_dir, \"trained_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliação\n",
    "def evaluate_model(val_images, val_labels, model, results_dir):\n",
    "    predictions = model.predict(val_images)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    report = classification_report(val_labels, predicted_classes, target_names=class_labels, output_dict=True)\n",
    "    \n",
    "    with open(os.path.join(results_dir, \"classification_report.txt\"), \"w\") as f:\n",
    "        f.write(classification_report(val_labels, predicted_classes, target_names=class_labels))\n",
    "    print(\"Classification Report:\\n\", classification_report(val_labels, predicted_classes, target_names=class_labels))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(val_labels, predicted_classes)\n",
    "    \n",
    "    # Normalizar a matriz de confusão para porcentagens\n",
    "    conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    np.savetxt(os.path.join(results_dir, \"confusion_matrix.txt\"), conf_matrix, fmt='%d')\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(conf_matrix_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "    \n",
    "    # Adicionando os rótulos com porcentagens\n",
    "    thresh = conf_matrix_normalized.max() / 2.\n",
    "    for i, j in np.ndindex(conf_matrix_normalized.shape):\n",
    "        plt.text(j, i, f'{conf_matrix_normalized[i, j]:.2%}', \n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix_normalized[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Exibindo as métricas\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "evaluate_model(val_images, val_labels, model, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar e salvar o histórico de treinamento\n",
    "def plot_history(history, results_dir):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "    plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "    plt.title('Acurácia ao Longo das Épocas')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "    plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "    plt.title('Perda ao Longo das Épocas')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, \"training_history.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plot_history(history, results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
